{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<p style=\"background-color:#5B5EA6;font-family:newtimeroman;color:white;font-size:250%;text-align:center;\">Choose the Ideal Site for Designing Your Restaurant Using Data Science</p>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:#5B5EA6;\"><span style=\"font-family:cursive; font-size:25px; color:white;\"> TABLE OF CONTENTS  üìù</span></div>\n<div style=\"font-family:newtimeroman; color:crimson;font-size:19px;background-color:white\">\n<ul >\n    \n<li><a href = \"#1\"> 1. Introduction </a></li>     \n<li ><a href = \"#2\"> 2. Data information </a></li> \n<li ><a href = \"#3\"> 3. Preparations </a></li>    \n<ul>\n<li ><a  href = \"#3.1\"> 3.1 Load Libraries </a></li>\n<li ><a  href = \"#3.2\"> 3.2 Data selection and preprocessing </a></li>\n</ul>\n    \n<li><a href = \"#4\"> Visualization of collected data </a></li>\n<ul> \n<li  ><a href = \"#4.1\">4.1 Visualizing Boston area</a></li>\n<li  ><a href = \"#4.2\">4.2 Visualizing restaurent density</a></li>\n<li  ><a href = \"#4.3\">4.3 Visualizing population density</a></li>    \n</ul>  \n      \n<li ><a  href = \"#5\"> 5. Analysis of collected data </a></li>\n<ul> \n<li  ><a href = \"#5.1\">5.1 Preprocessing data for analysis</a></li>\n<li  ><a href = \"#5.2\">5.2 K-Means Analysis</a></li>\n<li  ><a href = \"#5.3\">5.3 Principle component Analysis</a></li>    \n</ul>  \n\n<li ><a  href = \"#6\"> 6.Results</a></li>\n<li ><a  href = \"#7\"> 7. Ref</a></li>\n</ul>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<div id='1' style=\"background-color:#5B5EA6;\"><span style=\"font-family:cursive; font-size:25px; color:white;\"> INTRODUCTION  üìù</span></div>\n<p style=\"font-family:newtimeroman;color:crimson;font-size:19px;background-color:white\">Site analysis has a major role in placing a building, especially shopping malls,Shops, restaurant. Here we are trying to find some insights that help us to place our restaurant based on food type we are serving, characteristics of people who lives there, financial stability of people, demographic characteristics of the place, labor force etc.The analysis not only help owners to find ideal sites but also people to enjoy their favorite foods. Here the project tries to find locations of restaurants in Boston,is the capital and most populous city of the Commonwealth of Massachusetts in the United States. </p>","metadata":{}},{"cell_type":"markdown","source":"<div id=\"2\" style=\"background-color:#5B5EA6;\"><span style=\"font-family:cursive; font-size:25px; color:white;\"> DATA INFORMATIONüìù</span></div>\n<div style=\"font-family:newtimeroman;color:crimson;font-size:19px;background-color:white\">\n<p >\n    Data is collected from various channels and resources.Here we have used three major data sets .</p>\n<ul>\n    <li><h4>Geojson dataset of boston</h4>\nGeoJSON is an open standard geospatial data interchange format that represents simple geographic features and their nonspatial attributes. <a style=\"color:  blue\" href=\"https://data.boston.gov/dataset/boston-neighborhoods1\" target=\"_blank\"> <u>Link to the Dataset</u></a></li>\n    <li><h4>List of Restaurents in boston </h4>The Health Division of the Department of Inspectional Services (ISD) creates and enforces food safety codes to protect public health. All businesses which prepare and sell food to the public must possess a food service permit. In order to qualify for a permit, at least one full time employee must be must be certified through an accredited food manager program, which provides guidance on handling and serving food to the public.This dataset contains a list of restaurants that met the City's standards to become licensed food service establishments.<a style=\"color:  blue\" href=\"https://data.boston.gov/dataset/active-food-establishment-licenses/resource/f1e13724-284d-478c-b8bc-ef042aa5b70b\" target=\"_blank\"> <u>Link to the Dataset</u></a></li>\n   <li><h4>Neighbourhood survey results 2015-2018</h4>Boston in Context- Neighborhoods compares the United States, Massachusetts,Boston, and Boston‚Äôs neighborhoods across several social, economic, and housing characteristics. These data are from the 2014-2018 American Community Survey (ACS)<a style=\"color:  blue\" href=\"http://www.bostonplans.org/getattachment/1882b00d-48fe-41bc-ac1a-6979e25dbaf1\" target=\"_blank\"> <u>Link to the Dataset</u></a></li>\n</ul>\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div id=\"3\" style=\"background-color:#5B5EA6;\"><span style=\"font-family:cursive; font-size:25px; color:white;\"> PREPARATIONSüìù</span></div>\n<div style=\"font-family:newtimeroman;color:crimson;font-size:19px;background-color:white\">\n<p >\n    Preparation of data includes importing libraries, selecting and converting data into structerd form </p>\n<ul>\n <li><a  href=\"#11\" target=\"_blank\"> <h4>Loading libraries</h4></a></li>\n     <li><a  href=\"#1\" target=\"_blank\"> <h4>Data gathering and preprocessing</h4></a></li>\n   \n   \n</ul>\n\n</div>","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"<div id=\"3.1\" style=\"background-color:#5B5EA6;\"><span style=\"font-family:cursive; font-size:25px; color:white;\"><li>Loading libraries</li></span></div>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport geojson\nimport json  \nimport folium\nimport os \nfrom sklearn.cluster import KMeans\nimport numpy as np\n!pip install \"camelot-py[cv]\"","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:07:46.426997Z","iopub.execute_input":"2022-02-21T14:07:46.427963Z","iopub.status.idle":"2022-02-21T14:08:02.21467Z","shell.execute_reply.started":"2022-02-21T14:07:46.427851Z","shell.execute_reply":"2022-02-21T14:08:02.213735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div id=\"3.2\" style=\"background-color:#5B5EA6;\"><span style=\"font-family:cursive; font-size:25px; color:white;\"><li>Data selection and preprocessing</li></span></div>\n<div style=\"font-family:newtimeroman;color:crimson;font-size:19px;background-color:white\">\n<p >Collected dataset is in three types of formats. <br>\n    third one is pdf report of survey. Our aim is to convert the pdf to CSV format .</p>\n<ul>\n    <li><h4>Geojson dataset of boston</h4>\nGDemographic data is in geoJson format where we can use sdirectly for plotting the boundries. This dataset is in GEOJSON fomrat</li>\n  <li><h4>Resturnet dataset of boston</h4>\nList of all food serving places in boston area. This dataset is in CSV fomrat.having columns{}.Dataset needs to be cleaned to get accurate locations of the restaurents.accuracy lies in two columns one is the city name of the restaurent situated and it's coordinates.Some rows missing the city names but, it has coordinates.Some restaurents misses the coordinates but has address of the restaurent.Our aim is to convert longitude and latitude of rest to city names and vice versa </li>\n  <li><h4>Survey data </h4>\nNeighborhoods compares the United States, Massachusetts,Boston, and Boston‚Äôs neighborhoods across several social, economic, and housing characteristics.Our aim is to extract useful information about neighbourhood which helps us in placing the restaurent.We predefined the featres such as{ poppulation, median age , Occupation , family income , industries,vehicles per housse hold, household income, number of housing units, poverty rates, percapita income, area, total houses , workers number until age 29 ,workers number until age  52} </li>\n \n</ul>\n\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"font-family:newtimeroman;color:crimson;font-size:19px;background-color:white\"><h4><li>Restaurent dataset</li></h4>\n <p>Converitng city names to longitude and latitude and vice versa using geopy library (geopy makes it easy for Python developers to locate the coordinates of addresses, cities, countries, and landmarks across the globe using third-party geocoders and other data sources) </p></div>","metadata":{}},{"cell_type":"code","source":"from geopy.geocoders import Nominatim\ngeolocator = Nominatim(user_agent='firefox')\nrest_coord_n=pd.read_csv('../input/res-boston/rest_boston.csv')\nrest_coord=rest_coord_n.copy()\nrest_coord.loc[rest_coord['Longitude'] == 0.0,'Longitude']=str(2)\nrest_coord.loc[rest_coord['Latitude'] == 0.0,'Latitude']=str(2)\nfor i in range(len(rest_coord['CITY'])):\n    if  str(rest_coord['CITY'].iloc[i]) == 'Boston':\n        if str(rest_coord.iloc[i]['Latitude'])+','+str(rest_coord.iloc[i]['Longitude']) != '2,2':\n            \n            try:\n                \n               #print(str(rest_coord.iloc[i]['Latitude'])+','+str(rest_coord.iloc[i]['Longitude']))\n                location = geolocator.reverse(str(rest_coord.iloc[i]['Latitude'])+','+str(rest_coord.iloc[i]['Longitude']))\n                location=location.raw['address']['suburb'].replace('Boston','')\n                #print(rest_coord['CITY'].iloc[i])\n                rest_coord['CITY'].iloc[i]=rest_coord['CITY'].iloc[i].replace(str(rest_coord['CITY'].iloc[i]),str(location))\n               # print(rest_coord['CITY'].iloc[i])\n            except:\n                rest_coord['CITY'].iloc[i]=rest_coord['CITY'].iloc[i].replace(str(rest_coord['CITY'].iloc[i]),\"NaN\")\n                \n            \n        else:\n                try:\n                    \n                    ad=str(rest_coord.iloc[i]['Address']+' '+ rest_coord.iloc[i]['CITY']+' United States')\n                   # print(\"'\"+ad+\"'\")\n                    location = geolocator.geocode(ad)\n\n                    rest_coord['Latitude'].iloc[i]=rest_coord['Latitude'].iloc[i].replace(str(rest_coord['Latitude'].iloc[i]),str(location.latitude))\n                    rest_coord['Longitude'].iloc[i]=rest_coord['Longitude'].iloc[i].replace(str(rest_coord['Longitude'].iloc[i]),str(location.longitude))\n                    \n                    try:\n                        \n                        location = geolocator.reverse(str(rest_coord.iloc[i]['Latitude'])+','+str(rest_coord.iloc[i]['Longitude']))\n                        location=location.raw['address']['suburb'].replace('Boston','')\n                        #print(rest_coord['CITY'].iloc[i])\n                        rest_coord['CITY'].iloc[i]=rest_coord['CITY'].iloc[i].replace(str(rest_coord['CITY'].iloc[i]),str(location))\n                       # print(rest_coord['CITY'].iloc[i])\n                    except:\n                        rest_coord['CITY'].iloc[i]=rest_coord['CITY'].iloc[i].replace(str(rest_coord['CITY'].iloc[i]),\"NaN\")\n                \n                except:\n                    rest_coord['Latitude'].iloc[i]=rest_coord['Latitude'].iloc[i].replace(str(rest_coord['Latitude'].iloc[i]),'NaN')\n                    rest_coord['Longitude'].iloc[i]=rest_coord['Longitude'].iloc[i].replace(str(rest_coord['Longitude'].iloc[i]),'NaN')\n\n\nrest_coord['Latitude']=rest_coord['Latitude'].astype('str')\nrest_coord['Longitude']=rest_coord['Longitude'].astype('str')\nrest_coord=rest_coord[rest_coord['Latitude'] != '2']\nrest_coord=rest_coord[rest_coord['Latitude']!='NaN']\nrest_coord=rest_coord[rest_coord['Longitude']!='NaN']","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:08:02.216519Z","iopub.execute_input":"2022-02-21T14:08:02.216772Z","iopub.status.idle":"2022-02-21T14:24:26.402811Z","shell.execute_reply.started":"2022-02-21T14:08:02.216743Z","shell.execute_reply":"2022-02-21T14:24:26.401211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:newtimeroman;color:crimson;font-size:19px;background-color:white\"><h4><li> Survey dataset</li></h4>\n <p>Extracting { population, median age , Occupation , family income , industries,vehicles per housse hold, household income, number of housing units, poverty rates, percapita income, area, total houses , workers number until age 29 ,workers number until age  52}  </p></div>","metadata":{}},{"cell_type":"code","source":"#1Reading pdf and converitng all pages to .csv\nimport camelot\ntables=camelot.read_pdf('../input/boston-all-data/Boston-in-Context-09-13_NEIGH_final_version_KW_2015-8-4.pdf', flavor='stream', pages='5-34')\n#creating dataset with the following column names\ncolumns=['name','population','median age' ,'Occupation' ,'family income' ,'industries','vehicles per house hold', 'household income','housing units','poverty rates','percapita income', 'area', 'workers until 29' ,'workers until 52', 'restaurant number','restaurant density']\nrest_data = pd.DataFrame(columns=columns)\nfor i in range(30):\n    tables[i].df.to_csv(str(i)+'.csv')\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:24:26.405593Z","iopub.execute_input":"2022-02-21T14:24:26.40605Z","iopub.status.idle":"2022-02-21T14:26:12.831677Z","shell.execute_reply.started":"2022-02-21T14:24:26.405981Z","shell.execute_reply":"2022-02-21T14:26:12.830815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#2 Adding extracted informations to the newly created dataframe from the CSV file \nage=pd.read_csv('./0.csv')\npercapita_income=pd.read_csv('./12.csv')\npercapita_income.columns=percapita_income.iloc[0]\npercapita_income.drop([0],axis=0,inplace=True)\n\nage.drop([0,1,2],axis=0,inplace=True)\nage=age.rename({'0':'name'},axis=1)\nrest_data['name']=list(percapita_income['Per Capita and Aggregate Income'])\n\nrest_data=rest_data.join(age.set_index('name')['2'],on='name')\nrest_data=rest_data.drop('median age',axis=1).rename({'2':'median age'},axis=1)\n\n\nrest_data['population']=list(percapita_income['Total Population'])\nrest_data['percapita income']=list(percapita_income['Per Capita Income'])\n\n#occupation\noccupation=pd.read_csv('./13.csv')\n#percapita_income.columns=percapita_income.iloc[0]\noccupation.drop([0,1,2,3,4],axis=0,inplace=True)\nrest_data['Occupation']=list(occupation['1'])\n\n#family income\nfamily_income=pd.read_csv('./23.csv')\nfamily_income.drop([0,1,2],axis=0,inplace=True)\n\nrest_data['family income']=list(family_income['1'])\nhousehold_income=pd.read_csv('./22.csv')\nhousehold_income.drop([0,1,2],axis=0,inplace=True)\n\nrest_data['household income']=list(household_income['1'])\n\n#industries\nindustries=pd.read_csv('./14.csv')\nindustries.drop([0,1,2],axis=0,inplace=True)\nrest_data['industries']=list(industries['1'])\n#vehicles per household\nvehicles=pd.read_csv('./26.csv')\nvehicles.drop([0,1,2,3],axis=0,inplace=True)\nrest_data['vehicles per household']=list(vehicles['1'])\n#number houses\nhouses=pd.read_csv('./24.csv')\nhouses.drop([0,1,2,3],axis=0,inplace=True)\nhouses=houses.rename({'0':'name'},axis=1)\n#houses['2']=houses['2'].dropna()\n#rest_data['housing units']=list(houses)\nrest_data=rest_data.join(houses.set_index('name')['2'],on='name')\nrest_data=rest_data.drop('housing units',axis=1)\nrest_data=rest_data.rename({'2':'housing units'},axis=1)\n#poverty rates\npoverty_rates=pd.read_csv('./27.csv')\npoverty_rates.drop([0],axis=0,inplace=True)\npoverty_rates=list(poverty_rates['2'])\nrest_data['poverty rates']=poverty_rates\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:26:12.833654Z","iopub.execute_input":"2022-02-21T14:26:12.833894Z","iopub.status.idle":"2022-02-21T14:26:12.89309Z","shell.execute_reply.started":"2022-02-21T14:26:12.833866Z","shell.execute_reply":"2022-02-21T14:26:12.892201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#4\n#creating dataset with two features , Boston neighbourhood and Number of restaurents in each neighbourhood\nrest_counts={}\n\nfor i in set(rest_coord['CITY']):\n    \n    count=len(rest_coord[rest_coord['CITY']==str(i)])\n    \n    if (i.strip().lower().replace('/','').title() in rest_counts.keys()):\n        \n                rest_counts[i.strip().lower().replace('/','').title()]=rest_counts[i.strip().lower().replace('/','').title()]+count\n    else:\n        rest_counts[i.strip().lower().replace('/','').title().strip()]=count\n        \n        \n            \n\nrest_count=pd.DataFrame(rest_counts.keys())\nrest_count['num']=list(rest_counts.values())\nrest_count.drop(2,axis=0,inplace=True)\n\nrest_count=rest_count.replace('Downtownfinancial District','Downtown')\nrest_count=rest_count.replace('South','South Boston')\nrest_count=rest_count.replace('East','East Boston')\nrest_count=rest_count.replace('Fenway-Kenmore','Fenway')\nrest_count=rest_count.drop(0,axis=0).reset_index()\nrest_count=rest_count.rename({0:'name'},axis=1)\n\nrest_count=rest_count.drop(rest_count[rest_count['num']==1].index)\nrest_count['name']=rest_count['name'].apply(lambda x  : x.strip())\nres = rest_count.groupby('name', as_index=False).sum()\nrest_count=res.drop('index',axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T15:47:05.718203Z","iopub.execute_input":"2022-02-21T15:47:05.718515Z","iopub.status.idle":"2022-02-21T15:47:05.76545Z","shell.execute_reply.started":"2022-02-21T15:47:05.718476Z","shell.execute_reply":"2022-02-21T15:47:05.764254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#5Adding area of neighbourhoods.\narea=pd.read_csv('../input/area-boston/Boston_Neighborhoods.csv')\narea=area.rename({'Name':'name'},axis=1)\narea.head(2)\n#6\nrest_data=rest_data.join(area.set_index('name')['SqMiles'],on='name')\nrest_data=rest_data.join(rest_count.set_index('name')['num'],on='name')\nrest_data=rest_data.drop(['area','restaurant number'],axis=1)\nrest_data['SqMiles']=rest_data['SqMiles']*2.58\n\n#7Calculating restaurent density using number area / number of resturents\nrest_data['restaurant density']=rest_data['num']/rest_data['SqMiles']\n\nlabour=pd.read_csv('./16.csv')\n\nlabour.drop([0,1,2],axis=0,inplace=True)\n\nrest_data['workers until 52']=list(labour['1'])\n#deleting workforce number until age 29\nrest_data=rest_data.drop('workers until 29',axis=1)\n\n#8\n#renaming \nrest_data=rest_data.rename({'num':'number_rest','workers until 52':'labour force','SqMiles':'SqKm'},axis=1)\nrest_data['percapita income']=rest_data['percapita income'].apply(lambda x : x.replace('$',''))\nrest_data=rest_data.drop('Occupation',axis=1)\nrest_data.to_csv('rest_data.csv')\n\n#10\nrest_data_clean=rest_data.copy()\nrest_data_clean=rest_data_clean.drop([0,1,2],axis=0)\nrest_data_clean['population']=rest_data_clean['population'].apply(lambda x: int(float((str(x).replace(\",\", \"\")))))\nrest_data_clean['restaurant density']=rest_data_clean['restaurant density'].fillna(0)\nrest_data_clean['population density']=rest_data_clean['population']/rest_data_clean['SqKm']\nrest_data_clean=rest_data_clean.fillna(0)\nrest_data_clean","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:26:12.952971Z","iopub.execute_input":"2022-02-21T14:26:12.953201Z","iopub.status.idle":"2022-02-21T14:26:13.018662Z","shell.execute_reply.started":"2022-02-21T14:26:12.953172Z","shell.execute_reply":"2022-02-21T14:26:13.017829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rest_data_clean.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:58:45.978998Z","iopub.execute_input":"2022-02-21T14:58:45.979815Z","iopub.status.idle":"2022-02-21T14:58:45.993197Z","shell.execute_reply.started":"2022-02-21T14:58:45.97977Z","shell.execute_reply":"2022-02-21T14:58:45.991858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div id=\"4\" style=\"background-color:#5B5EA6;\"><span style=\"font-family:cursive; font-size:25px; color:white;\"> VISUALIZATION OF COLLECTED DATA üìù</span></div>\n<div style=\"font-family:newtimeroman;color:crimson;font-size:19px;background-color:white\">\n<p >\n   Visualization of data includes showing the studied area and competitor restaurant locations.</p>\n<ul>\n <li><a  href=\"#4.1\" target=\"_blank\"> <h4>Visualizing Boston area</h4></a></li>\n     <li><a  href=\"#4.2\" target=\"_blank\"> <h4>Visualizing restaurent density</h4></a></li>\n     <li><a  href=\"#4.3\" target=\"_blank\"> <h4>Visualizing population density</h4></a></li>\n   \n   \n</ul>\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div id=\"4.1\" style=\"background-color:#5B5EA6;\"><span style=\"font-family:cursive; font-size:25px; color:white;\"><li>Visualizing Boston area </li></span></div>\n","metadata":{}},{"cell_type":"code","source":"neighbour=open('../input/gjson-boston/Boston_Neighborhoods.geojson')\ngdata=geojson.load(neighbour)\ncenter_cor_boston=[42.3601, -71.0589] \nboston_map = folium.Map(location=center_cor_boston, zoom_start=12,)\nboston_map.choropleth(geo_data=gdata,    fill_color='red',\n    fill_opacity=0.2,\n    line_opacity=1,)\nboston_map","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:26:13.037695Z","iopub.execute_input":"2022-02-21T14:26:13.037942Z","iopub.status.idle":"2022-02-21T14:26:13.577312Z","shell.execute_reply.started":"2022-02-21T14:26:13.037904Z","shell.execute_reply":"2022-02-21T14:26:13.57571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div  id=\"4.2\"  style=\"background-color:#5B5EA6;\"><span style=\"font-family:cursive; font-size:25px; color:white;\"><li>Population and restaurent density of Boston </li></span></div>\n","metadata":{}},{"cell_type":"code","source":"center_cor_boston=[42.3601, -71.0589] \nm=folium.Map(location=center_cor_boston)\n\nm.choropleth(\n    geo_data=gdata,\n    name='population',\n    data=rest_data_clean,\n    columns=['name', 'population density'],\n    key_on='properties.Name',\n    fill_color='YlGn',\n    fill_opacity=0.7,\n    line_opacity=0.2,\n    legend_name='Population Density' \n)\nm.choropleth(\n    geo_data=gdata,\n    name='restaurent',\n    data=rest_data_clean,\n    columns=['name', 'restaurant density'],\n    key_on='properties.Name',\n    fill_color='YlGn',\n    fill_opacity=0.7,\n    line_opacity=0.2,\n    legend_name='Restaurant Density' \n)\nfolium.LayerControl().add_to(m)\nm","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:26:13.57837Z","iopub.execute_input":"2022-02-21T14:26:13.578951Z","iopub.status.idle":"2022-02-21T14:26:14.030383Z","shell.execute_reply.started":"2022-02-21T14:26:13.57892Z","shell.execute_reply":"2022-02-21T14:26:14.02916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div  id=\"4.3\"  style=\"background-color:#5B5EA6;\"><span style=\"font-family:cursive; font-size:25px; color:white;\"><li>Restaurent locations, population and restaurent density of Boston </li></span></div>","metadata":{}},{"cell_type":"code","source":"#11\ncenter_cor_boston=[42.3601, -71.0589] \nm=folium.Map(location=center_cor_boston)\n\nm.choropleth(\n    geo_data=gdata,\n    name='population',\n    data=rest_data_clean,\n    columns=['name', 'population density'],\n    key_on='properties.Name',\n    fill_color='YlGn',\n    fill_opacity=0.7,\n    line_opacity=0.2,\n    legend_name='Population Density' \n)\nm.choropleth(\n    geo_data=gdata,\n    name='restaurent',\n    data=rest_data_clean,\n    columns=['name', 'restaurant density'],\n    key_on='properties.Name',\n    fill_color='YlGn',\n    fill_opacity=0.7,\n    line_opacity=0.2,\n    legend_name='Resturant Density' \n)\nfor r in range(len(rest_coord)):\n    \n    folium.CircleMarker([rest_coord.iloc[r]['Latitude'],rest_coord.iloc[r]['Longitude']], radius=1, color='red', fill=True,fill_color='red', fill_opacity=1).add_to(m)\nfolium.LayerControl().add_to(m)\nm","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:26:14.033576Z","iopub.execute_input":"2022-02-21T14:26:14.033844Z","iopub.status.idle":"2022-02-21T14:26:16.650737Z","shell.execute_reply.started":"2022-02-21T14:26:14.033814Z","shell.execute_reply":"2022-02-21T14:26:16.649505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div  id=\"5\" style=\"background-color:#5B5EA6;\"><span style=\"font-family:cursive; font-size:25px; color:white;\"> ANALYSIS OF COLLECTED DATA</span></div>\n<div style=\"font-family:newtimeroman;color:crimson;font-size:19px;background-color:white\">\n<p >\n   Visualization of data includes showing the studied area and competitor restaurant locations.</p>\n<ul>\n    ANALYSIS OF COLLECTED DATA \n <li><a  href=\"#5.1\" target=\"_blank\"> <h4>Preprocessing data for analysis</h4></a></li>\n     <li><a  href=\"#5.2\" target=\"_blank\"> <h4>K-Means Analysis </h4></a></li>\n     <li><a  href=\"#5.3\" target=\"_blank\"> <h4>Principle component Analysis</h4></a></li>\n   \n   \n</ul>\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div  id=\"5.1\"  style=\"background-color:#5B5EA6;\"><span style=\"font-family:cursive; font-size:25px; color:white;\"><li>Preprocessing data</li></span></div>\n<div style=\"font-family:newtimeroman;color:crimson;font-size:19px;background-color:white\">\n    <p>Preprocessing of data includes two steps:</p>\n<ul>\n    <li><h4>Removing unwanted columns and replacing values</h4>\n        <p>\n</li>\n     <li><h4>Scaling the features</h4>\n</li>\n    </ul>\n    </div>\n","metadata":{}},{"cell_type":"code","source":"#let do kmeans \n#removing the following columns\nclust_data=rest_data_clean.drop(['population','number_rest','SqKm'],axis=1)\n#replacing infinite values, Null  values(-) with 0\nfor col in clust_data.columns:\n    clust_data[col]=clust_data[col].apply(lambda x : str(x).replace(',',''))\n    clust_data[col]=clust_data[col].apply(lambda x : str(x).replace('-','0'))\n    clust_data[col]=clust_data[col].apply(lambda x : str(x).replace('inf','0'))\n#All the features are numerical values, lets scale it\nfrom sklearn.preprocessing import StandardScaler\nclust_data.isna().sum()\nclust_data.set_index('name',inplace=True)\nscaler = StandardScaler()\nclust_data_scaled= scaler.fit_transform(clust_data)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:26:16.652225Z","iopub.execute_input":"2022-02-21T14:26:16.652916Z","iopub.status.idle":"2022-02-21T14:26:16.685902Z","shell.execute_reply.started":"2022-02-21T14:26:16.652866Z","shell.execute_reply":"2022-02-21T14:26:16.68519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nX_scaled_clustered.drop('cluster',axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T15:21:56.146263Z","iopub.execute_input":"2022-02-21T15:21:56.146584Z","iopub.status.idle":"2022-02-21T15:21:56.176115Z","shell.execute_reply.started":"2022-02-21T15:21:56.146553Z","shell.execute_reply":"2022-02-21T15:21:56.175165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"<div  id=\"5.2\"  style=\"background-color:#5B5EA6;\"><span style=\"font-family:cursive; font-size:25px; color:white;\"><li>K-Means Analysis</li></span></div>\n<div style=\"font-family:newtimeroman;color:crimson;font-size:19px;background-color:white\">\n    <p>Kmeans analysis has three steps.:</p>\n<ul>\n    <li><h4>Choosing number of clusters</h4>\n        <p>\n</li>\n     <li><h4>Clutering the data into selected number of clusters</h4>\n</li>\n    <li><h4>Intrepreting the clusters</h4></li>\n    </ul>\n    </div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"font-family:newtimeroman;color:crimson;font-size:19px;background-color:white\"><h4><li> Choosing number of clusters for analysis</li></h4>\n <p>Choosing the clusters using Elbow curve </p></div>","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n# Run a number of tests, for 1, 2, ... num_clusters\nnum_clusters = 15\nkmeans_tests = [KMeans(n_clusters=i, init='random', n_init=10) for i in range(1, num_clusters)]\nscore = [kmeans_tests[i].fit(clust_data_scaled).score(clust_data_scaled) for i in range(len(kmeans_tests))]\n\n# Plot the curve\nplt.plot(range(1, num_clusters),score)\nplt.xlabel('Number of Clusters')\nplt.ylabel('Score')\nplt.title('Elbow Curve')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:26:16.686935Z","iopub.execute_input":"2022-02-21T14:26:16.687481Z","iopub.status.idle":"2022-02-21T14:26:17.231304Z","shell.execute_reply.started":"2022-02-21T14:26:16.687447Z","shell.execute_reply":"2022-02-21T14:26:17.230157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:newtimeroman;color:crimson;font-size:19px;background-color:white\">\n<ul><b style=\"font-size:25px\">We find:</b>    \n<li>6 selected as number of clusters</li>\n\n</ul>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"font-family:newtimeroman;color:crimson;font-size:19px;background-color:white\"><h4><li>Clustering the data into slected number of clusters</li></h4>\n <p>Data is transformed into 6 clusters and saved cluster number as a new column in the dataframe X_scaled_cluster </p></div>","metadata":{}},{"cell_type":"code","source":"kmeans = KMeans(n_clusters=6, random_state=0).fit(clust_data_scaled)\nkmeans.fit(clust_data_scaled)\nclusters =  kmeans.predict(clust_data_scaled)\n\nX_scaled_clustered = pd.DataFrame(clust_data_scaled, columns=clust_data.columns, index=clust_data.index)\nX_scaled_clustered['cluster'] = clusters\nX_scaled_clustered=X_scaled_clustered.reset_index()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:26:17.233007Z","iopub.execute_input":"2022-02-21T14:26:17.233253Z","iopub.status.idle":"2022-02-21T14:26:17.300541Z","shell.execute_reply.started":"2022-02-21T14:26:17.233218Z","shell.execute_reply":"2022-02-21T14:26:17.299914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:newtimeroman;color:crimson;font-size:19px;background-color:white\"><h4><li>Intrepreting  the clusters</li></h4>\n <p>Visualizing the map of neighbourhoods based on the clluster number where it belongs </p></div>","metadata":{}},{"cell_type":"code","source":"#plotting graph using pop, res and cluster\n#11\nneighbour=open('../input/gjson-boston/Boston_Neighborhoods.geojson')\ngdata=geojson.load(neighbour)\ncenter_cor_boston=[42.3601, -71.0589] \nm=folium.Map(location=center_cor_boston)\n\n\nm.choropleth(\n    geo_data=gdata,\n    name='population',\n    data=X_scaled_clustered,\n    columns=['name', 'population density'],\n    key_on='properties.Name',\n    fill_color='YlGn',\n    fill_opacity=0.7,\n    line_opacity=0.2,\n    legend_name='Population Density' \n)\nm.choropleth(\n    geo_data=gdata,\n    name='restaurent',\n    data=X_scaled_clustered,\n    columns=['name', 'restaurant density'],\n    key_on='properties.Name',\n    fill_color='YlGn',\n    fill_opacity=0.7,\n    line_opacity=0.2,\n    legend_name='Resturant Density' \n)\nm.choropleth(\n    geo_data=gdata,\n    name='cluster',\n    data=X_scaled_clustered,\n    columns=['name', 'cluster'],\n    key_on='properties.Name',\n    fill_color='YlGn',\n    fill_opacity=0.7,\n    line_opacity=0.2,\n    legend_name='cluster' \n)\n\nfor r in range(len(rest_coord)):\n    \n    folium.CircleMarker([rest_coord.iloc[r]['Latitude'],rest_coord.iloc[r]['Longitude']], radius=1, color='red', fill=True,fill_color='red', fill_opacity=1).add_to(m)\nfolium.LayerControl().add_to(m)\nm","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:26:17.301743Z","iopub.execute_input":"2022-02-21T14:26:17.302109Z","iopub.status.idle":"2022-02-21T14:26:20.484306Z","shell.execute_reply.started":"2022-02-21T14:26:17.302068Z","shell.execute_reply":"2022-02-21T14:26:20.483679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:newtimeroman;color:crimson;font-size:19px;background-color:white\">\n <p>\nvisualizing the clusters using parallel coordinate plot (ref: https://www.data-to-viz.com/graph/parallel.html.Parallel plot) or parallel coordinates plot allows to compare the feature of several individual observations (series) on a set of numeric variables. Each vertical bar represents a variable and often has its own scale. (The units can even be different). Values are then plotted as series of lines connected across each axis.</p></div>\n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\npd.plotting.parallel_coordinates(\n    X_scaled_clustered.drop('name',axis=1), 'cluster', \n)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:26:20.4852Z","iopub.execute_input":"2022-02-21T14:26:20.485426Z","iopub.status.idle":"2022-02-21T14:26:20.899523Z","shell.execute_reply.started":"2022-02-21T14:26:20.485398Z","shell.execute_reply":"2022-02-21T14:26:20.898692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:newtimeroman;color:crimson;font-size:19px;background-color:white\">\n <p>\n     visualizing the centroid of clusters using parallel coordinate plot </p></div>","metadata":{}},{"cell_type":"code","source":"# Create a data frame containing our centroids\ncentroids = pd.DataFrame(kmeans.cluster_centers_, columns=X_scaled_clustered.drop(['name','cluster'],axis=1).columns)\ncentroids['cluster'] = centroids.index\nplt.figure(figsize=(20,10))\npd.plotting.parallel_coordinates(\n    centroids, 'cluster', \n)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:26:20.900738Z","iopub.execute_input":"2022-02-21T14:26:20.900978Z","iopub.status.idle":"2022-02-21T14:26:21.244957Z","shell.execute_reply.started":"2022-02-21T14:26:20.900949Z","shell.execute_reply":"2022-02-21T14:26:21.244296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(6):\n    \n    print(f\"cluster {i} {list(X_scaled_clustered[X_scaled_clustered['cluster']==i]['name'])}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:26:21.246107Z","iopub.execute_input":"2022-02-21T14:26:21.246494Z","iopub.status.idle":"2022-02-21T14:26:21.262461Z","shell.execute_reply.started":"2022-02-21T14:26:21.246454Z","shell.execute_reply":"2022-02-21T14:26:21.26155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:newtimeroman;color:crimson;font-size:19px;background-color:white\">\n<ul><b style=\"font-size:25px\">We find:</b>    \n<li>Every cluster have their own variations.<br>\ncluster 0 ['Brighton', 'East Boston', 'Hyde Park', 'Jamaica Plain', 'Mattapan', 'Roslindale', 'Roxbury', 'South Boston', 'South End', 'West Roxbury']<br>\ncluster 1 ['Allston', 'Fenway', 'Longwood Medical Area', 'Mission Hill']<br>\ncluster 2 ['Dorchester']<br>\ncluster 3 ['Charlestown', 'South Boston Waterfront', 'West End']<br>\ncluster 4 ['Back Bay', 'Beacon Hill', 'Downtown', 'North End']<br>\ncluster 5 ['Harbor Islands']\n </li>\n    \n    \n\n\n</ul>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div id=\"5.3\" style=\"background-color:#5B5EA6;\"><span style=\"font-family:cursive; font-size:25px; color:white;\"><li>Principle Component Analysis</li></span></div>\n<div style=\"font-family:newtimeroman;color:crimson;font-size:19px;background-color:white\">\n    <p>PCA analysis has three steps.:</p>\n<ul>\n    <li><h4>Finding Eigen vectors</h4>\n        <p>\n</li>\n     <li><h4>Scree plot: Variance vs Principle component  </h4>\n</li>\n    <li><h4>Biplot : PC1 vs PC2</h4></li>\n    </ul>\n    </div>","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\n# Create a PCA model to reduce our data to 2 dimensions for visualisation\npca = PCA()\npca.fit(clust_data_scaled)\n\nloadings = pca.components_.T\nnum_pc = pca.n_features_\npc_list = [\"PC\"+str(i) for i in list(range(1, num_pc+1))]\nloadings_df=pd.DataFrame(loadings)\nloadings_df.columns=pc_list\nloadings_df['variable'] = clust_data.columns.values\nloadings_df = loadings_df.set_index('variable')\n\n\ndef make_pretty(styler):\n    styler.set_caption(\"Eigen_analysis\")\n\n    styler.background_gradient(axis=None, vmin=5, vmax=5, cmap=\"YlGnBu\")\n    return styler\ns=loadings_df.style.pipe(make_pretty)\ncell_hover = {  # for row hover use <tr> instead of <td>\n    'selector': 'td:hover',\n    'props': [('background-color', 'orange')]\n}\n\nheaders = {\n    'selector': 'th:not(.index_name)',\n    'props': 'background-color: #000066; color: white;'\n}\ns.set_table_styles([cell_hover, headers])","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:26:21.271088Z","iopub.execute_input":"2022-02-21T14:26:21.271686Z","iopub.status.idle":"2022-02-21T14:26:21.37328Z","shell.execute_reply.started":"2022-02-21T14:26:21.271647Z","shell.execute_reply":"2022-02-21T14:26:21.372376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eigen_values=pca.explained_variance_\npercentage_eigen_values=pca.explained_variance_ratio_\ncumilative_ev=np.cumsum(pca.explained_variance_ratio_)\neigen_analysis=pd.DataFrame([eigen_values,percentage_eigen_values,cumilative_ev],columns=pc_list,index=['Eigen_values','% of EV','cumilative Ev'])\ns=eigen_analysis.style.pipe(make_pretty)\ns.set_table_styles([cell_hover, headers])","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:26:21.374408Z","iopub.execute_input":"2022-02-21T14:26:21.374627Z","iopub.status.idle":"2022-02-21T14:26:21.400513Z","shell.execute_reply.started":"2022-02-21T14:26:21.374599Z","shell.execute_reply":"2022-02-21T14:26:21.399668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#scree plot\nPC_values = np.arange(pca.n_components_) + 1\nplt.plot(PC_values, pca.explained_variance_ratio_, 'ro-', linewidth=2)\nplt.title('Scree Plot')\nplt.xlabel('Principal Component')\nplt.ylabel('Proportion of Variance Explained')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:26:21.401879Z","iopub.execute_input":"2022-02-21T14:26:21.402217Z","iopub.status.idle":"2022-02-21T14:26:21.596602Z","shell.execute_reply.started":"2022-02-21T14:26:21.402189Z","shell.execute_reply":"2022-02-21T14:26:21.595532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loadingplot(coeff,labels=None):\n    n = coeff.shape[0]\n    for i in range(n):\n        plt.arrow(0, 0, coeff[i,0], coeff[i,1],color = 'r',alpha = 0.5)\n        if labels is None:\n            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, features[i], color = 'g', ha = 'center', va = 'center')\n        else:\n            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, labels[i], color = 'g', ha = 'center', va = 'center')\n \n    \n    plt.xlim(-1,1)\n    plt.ylim(-1,1)\n    plt.title('Loading plot')\n    plt.xlabel(\"PC{}\".format(1))\n    plt.ylabel(\"PC{}\".format(2))\n    plt.grid()\nfeatures=clust_data.columns\nplt.figure(figsize=(20,10))    \nloadingplot(loadings[:,:2])\nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:32:27.817158Z","iopub.execute_input":"2022-02-21T14:32:27.817829Z","iopub.status.idle":"2022-02-21T14:32:28.073995Z","shell.execute_reply.started":"2022-02-21T14:32:27.817783Z","shell.execute_reply":"2022-02-21T14:32:28.073106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#biplot\nimport plotly.express as px\nX_reduced = pca.transform(clust_data_scaled)\nloadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n\nfig = px.scatter(X_reduced, x=0, y=1, color=X_scaled_clustered['cluster'])\n\nfor i, feature in enumerate(features):\n    fig.add_shape(\n        type='line',\n        x0=0, y0=0,\n        x1=loadings[i, 0],\n        y1=loadings[i, 1]\n    )\n    fig.add_annotation(\n        x=loadings[i, 0],\n        y=loadings[i, 1],\n        ax=0, ay=0,\n        xanchor=\"center\",\n        yanchor=\"bottom\",\n        text=feature,\n    )\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:31:54.878779Z","iopub.execute_input":"2022-02-21T14:31:54.879509Z","iopub.status.idle":"2022-02-21T14:31:57.204652Z","shell.execute_reply.started":"2022-02-21T14:31:54.879451Z","shell.execute_reply":"2022-02-21T14:31:57.204051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PC1=loadings_df['PC1'].sort_values(ascending=False)\nPC2=loadings_df['PC2'].sort_values(ascending=False)\nPC3=loadings_df['PC3'].sort_values(ascending=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T14:31:57.205947Z","iopub.execute_input":"2022-02-21T14:31:57.206255Z","iopub.status.idle":"2022-02-21T14:31:57.211795Z","shell.execute_reply.started":"2022-02-21T14:31:57.20623Z","shell.execute_reply":"2022-02-21T14:31:57.210982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca_out=pd.DataFrame(X_reduced) \npca_out.columns=pc_list\npca_out['name']=list(rest_data_clean['name'])\npca_out.set_index('name',inplace=True)\nPC1_cntry=pca_out['PC1'].sort_values(ascending=False)\nPC2_cntry=pca_out['PC2'].sort_values(ascending=False)\nPC3_cntry=pca_out['PC3'].sort_values(ascending=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div id=\"6\"style=\"background-color:#5B5EA6;\"><span style=\"font-family:cursive; font-size:25px; color:white;\">RESULTSüìù</span></div>\n<div style=\"font-family:newtimeroman;color:crimson;font-size:19px;background-color:white\">\n<p >\n    Interpretation from KMEANS</p>\n<ul>\n    <li><h4>Cluster 2 has highest number of industries , vehicles,labor force , housing units,poverty rates</h4></li>\n<li><h4>cluster 4 has highest percapita income and restaurant density</h4></li>\n<li><h4>cluster 1 has lowest median age, Where youngsters are living</h4></li>\n<li><h4>cluster 5 has lowest house hold income and highest median age.where old age people lives</h4></li>\n</ul>\n    <p >\n    Interpretation from PCA</p>\n<ul>\n    <li><h4>PC1: This component is the measure of Labor force : 0.41 ,Healthcare: 0.40, Poverty rates: 0.40, industries: 0.40, housing units     0.40 and vehicles per house hold: .40 . Increase in  PC1 tends to increases the correlating values. PC1 describes 47% of variance.</h4></li>\n<li><h4>PC2: This component has can be measure of  percapita income: -0.482,House hold income  :  -0.43 ,family income  : 0.-43 and Population density:.37 . So, we can say PC2 tells about the Bad or worst. This suggest that when pc2 increases there will will be a low income.</h4></li>\n<li><h4>PC3:This component affects the Population density : 48% and restaurant density :46% also negatively affects median age. This component may say that area in PC3 have young people so, restaurant density is high.The third principal component is a measure of the age and restaurant density. </h4></li>\n\n</ul>\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div id=\"7\" style=\"background-color:#5B5EA6;\"><span style=\"font-family:cursive; font-size:25px; color:white;\">REF</span></div>\n<div style=\"font-family:newtimeroman;color:crimson;font-size:19px;background-color:white\">\n\n<ul>\n<li><h4>Restaurant Location and Planning Study by   Yimu Ding</h4></li>\n<li><h4>https://www.javatpoint.com/k-means-clustering-algorithm-in-machine-learning</h4></li>\n<li><h4>https://en.wikipedia.org/wiki/Principal_component_analysis</h4></li>\n<li><h4>https://www.data-to-viz.com/graph/parallel.html</h4></li>\n<li><h4>https://support.minitab.com/en-us/minitab/18/help-and-how-to/modeling-statistics/multivariate/how-to/principal-components/interpret-the-results/all-statistics-and-graphs/\n</h4></li>\n</ul>","metadata":{}}]}